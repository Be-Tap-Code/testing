#!/usr/bin/env python3
"""
Script Ä‘á»ƒ táº£i táº¥t cáº£ cÃ¡c frame tá»« cÃ¡c dataset Kaggle
"""
import os
import sys
import subprocess
import zipfile
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# Danh sÃ¡ch cÃ¡c dataset cáº§n táº£i
DATASETS = [
    {
        "name": "authienan/frame-l21-l23",
        "description": "Frame L21-L23",
        "expected_folders": ["L21", "L22", "L23"]
    },
    {
        "name": "authienan/frame-l24a-l25b", 
        "description": "Frame L24A-L25B",
        "expected_folders": ["L24", "L25"]
    },
    {
        "name": "qhiiine/frame-l26a-l26c",
        "description": "Frame L26A-L26C", 
        "expected_folders": ["L26"]
    },
    {
        "name": "qhiiine/frame-l26d-l27",
        "description": "Frame L26D-L27",
        "expected_folders": ["L26", "L27"]
    },
    {
        "name": "qhiiine/frame-l28-l30",
        "description": "Frame L28-L30",
        "expected_folders": ["L28", "L29", "L30"]
    }
]

def download_dataset(dataset_info):
    """Táº£i má»™t dataset tá»« Kaggle"""
    dataset_name = dataset_info["name"]
    description = dataset_info["description"]
    
    print(f"\nðŸ“¥ Downloading {description} ({dataset_name})...")
    
    # Táº¡o thÆ° má»¥c táº¡m cho dataset nÃ y
    temp_dir = Path(f"./temp_download_{dataset_name.replace('/', '_')}")
    temp_dir.mkdir(exist_ok=True)
    
    try:
        # Táº£i dataset
        cmd = ["kaggle", "datasets", "download", "-d", dataset_name, "-p", str(temp_dir)]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)  # 30 phÃºt timeout
        
        if result.returncode != 0:
            print(f"âŒ Failed to download {dataset_name}: {result.stderr}")
            return False, dataset_info, temp_dir
        
        print(f"âœ… Downloaded {description}")
        return True, dataset_info, temp_dir
        
    except subprocess.TimeoutExpired:
        print(f"â° Timeout downloading {dataset_name}")
        return False, dataset_info, temp_dir
    except Exception as e:
        print(f"âŒ Error downloading {dataset_name}: {e}")
        return False, dataset_info, temp_dir

def extract_dataset(dataset_info, temp_dir):
    """Giáº£i nÃ©n dataset"""
    dataset_name = dataset_info["name"]
    description = dataset_info["description"]
    
    print(f"ðŸ“¦ Extracting {description}...")
    
    try:
        # TÃ¬m file zip
        zip_files = list(temp_dir.glob("*.zip"))
        if not zip_files:
            print(f"âŒ No zip file found for {dataset_name}")
            return False
        
        zip_file = zip_files[0]
        
        # Giáº£i nÃ©n
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        
        print(f"âœ… Extracted {description}")
        return True
        
    except Exception as e:
        print(f"âŒ Error extracting {dataset_name}: {e}")
        return False

def move_frames_to_destination(dataset_info, temp_dir):
    """Di chuyá»ƒn frames vÃ o thÆ° má»¥c Ä‘Ã­ch"""
    dataset_name = dataset_info["name"]
    description = dataset_info["description"]
    print(f"ðŸ“‚ Moving frames from {description}...")
    frame_dir = Path("./frame")
    frame_dir.mkdir(exist_ok=True)
    moved_count = 0
    try:
        # TÃ¬m táº¥t cáº£ thÆ° má»¥c video trong temp_dir
        for item in temp_dir.rglob("*"):
            if item.is_dir() and item.name.startswith("L") and "_V" in item.name:
                dest_path = frame_dir / item.name
                if dest_path.exists():
                    print(f"   âš ï¸  {item.name} already exists, skipping...")
                    continue
                shutil.move(str(item), str(dest_path))
                moved_count += 1
                print(f"   âœ… Moved {item.name}")
        print(f"âœ… Moved {moved_count} video folders from {description}")
        return True
    except Exception as e:
        print(f"âŒ Error moving frames from {dataset_name}: {e}")
        return False

def cleanup_temp_dir(temp_dir):
    """Dá»n dáº¹p thÆ° má»¥c táº¡m"""
    try:
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
    except Exception as e:
        print(f"âš ï¸  Warning: Could not cleanup {temp_dir}: {e}")

def check_existing_frames():
    """Kiá»ƒm tra frames hiá»‡n cÃ³"""
    print("ðŸ“Š Checking existing frames...")
    
    frame_dir = Path("./frame")
    if not frame_dir.exists():
        print("âŒ Frame directory does not exist")
        return []
    
    existing_videos = []
    for item in frame_dir.iterdir():
        if item.is_dir():
            existing_videos.append(item.name)
    
    existing_videos.sort()
    print(f"ðŸ“ Found {len(existing_videos)} existing video folders:")
    for video in existing_videos[:10]:  # Show first 10
        print(f"   - {video}")
    
    if len(existing_videos) > 10:
        print(f"   ... and {len(existing_videos) - 10} more")
    
    return existing_videos

def process_dataset(dataset_info):
    """Xá»­ lÃ½ má»™t dataset hoÃ n chá»‰nh"""
    dataset_name = dataset_info["name"]
    description = dataset_info["description"]
    
    print(f"\n{'='*60}")
    print(f"ðŸš€ Processing {description}")
    print(f"{'='*60}")
    
    # BÆ°á»›c 1: Táº£i dataset
    success, dataset_info, temp_dir = download_dataset(dataset_info)
    if not success:
        cleanup_temp_dir(temp_dir)
        return False
    
    # BÆ°á»›c 2: Giáº£i nÃ©n
    if not extract_dataset(dataset_info, temp_dir):
        cleanup_temp_dir(temp_dir)
        return False
    
    # BÆ°á»›c 3: Di chuyá»ƒn frames
    if not move_frames_to_destination(dataset_info, temp_dir):
        cleanup_temp_dir(temp_dir)
        return False
    
    # BÆ°á»›c 4: Dá»n dáº¹p
    cleanup_temp_dir(temp_dir)
    
    print(f"ðŸŽ‰ Completed processing {description}")
    return True

def main():
    print("ðŸš€ AIC25 Frame Dataset Downloader")
    print("=" * 60)
    print("This script will download all frame datasets from Kaggle")
    print("=" * 60)
    
    # Kiá»ƒm tra frames hiá»‡n cÃ³
    existing_frames = check_existing_frames()
    
    print(f"\nðŸ“‹ Will download {len(DATASETS)} datasets:")
    for i, dataset in enumerate(DATASETS, 1):
        print(f"   {i}. {dataset['description']} ({dataset['name']})")
    
    # XÃ¡c nháº­n tá»« user
    response = input(f"\nâ“ Continue with download? (y/N): ").strip().lower()
    if response != 'y':
        print("âŒ Download cancelled by user")
        return
    
    print(f"\nðŸš€ Starting download process...")
    start_time = time.time()
    
    successful_downloads = 0
    failed_downloads = 0
    
    # Xá»­ lÃ½ tá»«ng dataset tuáº§n tá»± (Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i)
    for i, dataset_info in enumerate(DATASETS, 1):
        print(f"\nðŸ“Š Progress: {i}/{len(DATASETS)}")
        
        if process_dataset(dataset_info):
            successful_downloads += 1
        else:
            failed_downloads += 1
            print(f"âŒ Failed to process {dataset_info['description']}")
    
    # Tá»•ng káº¿t
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\n{'='*60}")
    print(f"ðŸŽ‰ Download process completed!")
    print(f"{'='*60}")
    print(f"âœ… Successful: {successful_downloads}/{len(DATASETS)} datasets")
    print(f"âŒ Failed: {failed_downloads}/{len(DATASETS)} datasets")
    print(f"â±ï¸  Total time: {duration/60:.1f} minutes")
    
    # Kiá»ƒm tra láº¡i frames sau khi táº£i
    print(f"\nðŸ“Š Final frame count:")
    final_frames = check_existing_frames()
    new_frames = len(final_frames) - len(existing_frames)
    print(f"ðŸ“ˆ Added {new_frames} new video folders")
    
    if successful_downloads > 0:
        print(f"\nâœ… You can now restart the backend server to index the new frames!")

if __name__ == "__main__":
    main()
